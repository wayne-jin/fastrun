# 线程池

### 不采用线程池时

创建线程->由该线程执行任务->任务执行完毕后销毁线程。即使需要使用到大量线程，每个线程都要按照这个流程来创建，执行，销毁。
虽然创建和销毁线程消耗的时间远小于线程执行的时间，但是对于需要频繁创建大量线程的任务，创建与销毁线程所占用的**时间与CPU资源**也会有很大的占比  

### 为了减少创建与销毁线程所带来的时间消耗和资源消耗，所以采用线程池的策略

程序启动后，**预先创建一定数量的线程放入空闲队列中，这些线程都是处于阻塞状态，基本不消耗CPU，只占用较小的内存空间**
接收到任务后，任务被挂在任务队列，线程池选择一个空闲线程来执行此任务
任务执行完毕后，不销毁线程，线程继续保持在池中等待下一次的任务  

### 线程池所解决的问题

1.需要频繁创建与销毁大量线程的情况下，由于线程预先就创建好了，接到任务就能马上从线程池中调用线程来处理任务，**减少了创建于销毁线程带来的时间开销和CPU资源开销**
2.需要并发的任务很多时候，无法为每个任务指定一个线程，使用线程池可以将提交的任务挂在任务队列上，等到池中有空闲的线程时就可以为该任务指定线程
![在这里插入图片描述](https://img-blog.csdnimg.cn/67c66d9b5740452fbf6bc4b8628e26ce.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5LiN5pGG54OC55qEenp6,size_16,color_FFFFFF,t_70,g_se,x_16)
如上图所示，工作队列由main线程和worker线程共享，主线程将任务放进工作队列，工作者线程从工作队列中取出任务执行
共享work queue的操作需在互斥量的保护下安全进行，主线程将任务放进工作队列时若检测到当前待执行的工作数目小于工作者线程总数，则需使用条件变量唤醒可能处于等待状态的工作者线程。当然，还有其他地方可能也会使用到互斥量和条件变量

```cpp
#include <vector>
#include <queue>
#include <thread>
#include <iostream>
#include <condition_variable>
using namespace std;
 
const int MAX_THREADS = 1000; //最大线程数目
 
template <typename T>
class threadPool
{
public:
    threadPool(int number = 1);
    ~threadPool();
    bool append(T *task);
    //工作线程需要运行的函数,不断的从任务队列中取出并执行
    static void *worker(void *arg);
    void run();
 
private:
    //工作线程
    vector<thread> workThread;
    //任务队列
    queue<T *> taskQueue;
    mutex mt;
    condition_variable condition;
    bool stop;
};

```
线程池的实现就有点像**生产者消费者模型**，append()就像是生产者，不断地将任务放入队列，run()函数就像消费者，不断地从任务队列中取出任何任务来处理，生产消费的两头分别用notify_one()和wait()来唤醒和阻塞

**构造函数**
构造函数中，创建N个线程(int number)，插入到工作线程当中，工作线程可以是vector结构

```cpp
template<typename T>
threadPool<T>::threadPool(int number) :stop(false) {
    if (number <= 0 || number > MAX_THREADS) {
        throw exception();
    }
    for (int i = 0; i < number; ++i) {
        cout << "create thread:" << i << endl;
        workThread.emplace_back(worker, this);
    }
}
```
工作线程中的线程具体要做什么呢？
1.进入线程的时候必须要用unique_lock进程加锁处理，不能让其他线程以及主线程影响到要处理的这个线程
2.判断任务队列是否为空，如果为空，则利用条件变量中的wait函数来阻塞该线程，等待任务队列不为空之后唤醒它
3.然后取出任务队列中的任务，执行任务中的具体操作

**析构函数**

```cpp
template<typename T>
inline threadPool<T>::~threadPool() {
    {
        unique_lock<mutex> unique(mt);
    }

    condition.notify_all();
    for(auto & wt:workThread)
        wt.join
}
```

**append**
接着将任务放入任务队列taskQueue,这里的任务是外部根据自己的业务自己定义的，可以是对象，可以是函数，结构体等等，而任务队列这里定义为queue结构，一定要记得将任务放入任务队列的时候，**要在之前加锁，放入之后再解锁**，这里的加锁解锁可以用unique_lock结构，当然也可以用mutex，而放入任务队列之后就可以用条件变量的notify_one()函数**通知阻塞的线程来取任务处理了**

```cpp
template<typename T>
bool threadPool<T>::append(T* task) {
    //往任务队列添加任务的时候，要加锁，因为这里是线程池，肯定有很多线程
    unique_lock<mutex> unique(mt);
    taskQueue.push(task);
    unique.unlock();
    //任务添加完之后，通知阻塞线程过来消费任务，有点像生产消费者模型
    condition.notify_one();
    return true;
}
```

**worker & run**

```cpp
template<typename T>
void *threadPool<T>::worker(void* arg) {
    threadPool* pool = (threadPool*)arg;
    pool->run();
    return pool;
}
```

```cpp
template<typename T>
void threadPool<T>::run() {
    while (!stop) {
        unique_lock<mutex> unique(this->mt);
        //如果任务队列为空，就停下来等待唤醒，等待另一个线程发来的唤醒请求
        while (this->taskQueue.empty())
            this->condition.wait(unique);
        T* task = this->taskQueue.front();
        this->taskQueue.pop();
        if (task)
            task->process();
    }
}
```

具体使用
写一个main文件来调用线程池的相关接口，main文件里定义一个任务对象，然后是main函数

```cpp
#include "threadPool.h"
#include <string>
using namespace std;
class Task
{
private:
    int total = 0;
 
public:
    void process();
};
 
//任务具体实现什么功能，由这个函数实现
void Task::process()
{
    //这里就输出一个字符串
    cout << "task successful！ " << endl;
    this_thread::sleep_for(chrono::seconds(1));
}
 
template class std::queue<Task>;
int main(void)
{
    threadPool<Task> pool(1);
    std::string str;
    while (1)
    {
        Task *task = new Task();
        pool.append(task);
        delete task;
    }
}
```

muluo采用的是固定大小的Reactor pool，**池子的大小通常根据CPU数目确定**。也就是说线程数固定，这样程序的总体处理能力不会随连接数增加而下降。另外一个连接完全由一个线程管理，那么请求的顺序性有保证，突发请求也不会占满8个核(如果需要优化突发请求，可以考虑Reactors + thread pool)这种方案把IO分派给多个线程，防止出现一个Reactor的处理能力饱和  


### 线程数是怎么设置的呢

线程数的设置需要考虑三方面的因素

* 服务器的配置
* 服务器资源的预算和
* 任务自身的特性

具体来说就是服务器有多少个CPU，多少内存，IO支持的最大QPS是多少，任务主要执行的是计算，IO还是一些混合操作，任务中是否包含数据库连接等的稀缺资源。线程池的线程数设置主要取决于这些因素  


###  具体是怎么设置呢？

假设机器有N个CPU

* 那么对于计算密集型的任务，应该设置线程数为N+1
* 对于IO密集型的任务，应该设置线程数为2N
* 对于同时又计算工作和IO工作的任务，应该考虑使用两个线程池，一个处理计算任务，一个处理IO任务，分别对两个线程池按照计算密集型和IO密集型来设置线程数  
  

### 假如在一个请求中，计算操作需要5ms,DB操作需要100ms,对于一台8个CPU的服务器，怎么设置线程数呢

这是一个计算和IO混合型的任务，可以将其分解为两个线程池来处理。一个线程池处理计算操作，设置N+1=9个线程，一个线程处理IO操作，设置2N=16个线程  


### **如果一个任务同时包含了一个计算操作和DB操作呢，不能拆分怎么设置？你能讲一下具体的计算过程么**

在处理一个请求的过程中，总共耗时100+5=105ms，而其中只有5ms是用于计算操作的，CPU利用率为5/(100+5)
假如以100%的CPU利用率来说，要达到100%的CPU利用率，对于一个CPU就要设置其利用率的倒数个数的线程数，也即1/(5/(100+5))，8个CPU的话就乘以8。105/5*8 =168  

### **如果实际的任务差异较大，不同任务实际的CPU操作耗时和IO操作耗时有所不同，那么怎么设置线程数呢？**  

那对所有任务的CPU操作耗时和IO操作耗时求个平均值就好了  


### **那如果现在这个IO操作时DB操作，而DB的QPS的上限时1000，这个线程池又该设置为多大呢**  

那按比例来减少就可以了，按照之前的计算过程，可以计算出来当线程数设置为168的时候，DB操作的QPS为，168*(1000/(100+5)) = 1600，如果现在DB的QPS最大为1000，那么对应的，最大只能设置168*(1000/1600) = 105个线程  


### **那设置线程池的时候除了考虑这些，还需要考虑哪些内容呢**

除了考虑任务CPU操作耗时，IO操作耗时之外，还需要服务器的内存资源，硬盘资源，网络带宽等等的  


### **N+1和2N是怎么来的？为什么不是N+2或者N+3，而非得是N+1呢**

计算密集型应用以第一种计算方式来看，最优的池大小等于
Nthreads = Ncpu * Ucpu *(1+w/c)

Ncpu = CPU的数量
Ucpu = 目标CPU的使用率
W/C = 阻塞时间/(阻塞时间+计算时间)

对于计算密集型应用，假定等待时间趋近于0，是的CPU利用率达到100%，W/C = 0, 那么线程数就是CPU核心数，

那这个+1意义何在呢？

计算密集型的线程恰好在某时因为发生一个页错误或者因其他原因而暂停，刚好有一个“额外”的线程，可以确保在这种情况下CPU周期不会中断工作。

IO密集型应用 同样以第一种方式来看，对于IO密集型应用，假定所有的操作时间几乎都是IO操作耗时，那么W/C的值就为1，那么对应的线程数确实为2N。
